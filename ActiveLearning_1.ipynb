{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As this is a regressor problem, any regression model will suffice. RandomForest seems to provide the best results."
      ],
      "metadata": {
        "id": "UhYLJu_52qsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/modAL-python/modAL.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rhSZmx_3j-j",
        "outputId": "f2cca138-5d2c-4b16-9efb-a4484e2e3020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/modAL-python/modAL.git\n",
            "  Cloning https://github.com/modAL-python/modAL.git to /tmp/pip-req-build-yjv0w7v7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modAL-python/modAL.git /tmp/pip-req-build-yjv0w7v7\n",
            "  Resolved https://github.com/modAL-python/modAL.git to commit bba6f6fd00dbb862b1e09259b78caf6cffa2e755\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.5.3)\n",
            "Collecting skorch==0.9.0 (from modAL-python==0.4.2)\n",
            "  Downloading skorch-0.9.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (0.8.10)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->modAL-python==0.4.2) (1.16.0)\n",
            "Building wheels for collected packages: modAL-python\n",
            "  Building wheel for modAL-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modAL-python: filename=modAL_python-0.4.2-py3-none-any.whl size=32654 sha256=ab8253fd9ef4dff94ee6f0f58bf92a009a86acfa7ab76ce245112065faa564f1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5386wvlw/wheels/d9/fb/59/7deb61b460c1c36394cd093758986ff7d36f71352dcb2e02c5\n",
            "Successfully built modAL-python\n",
            "Installing collected packages: skorch, modAL-python\n",
            "Successfully installed modAL-python-0.4.2 skorch-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "X, y = diabetes.data, diabetes.target\n",
        "\n",
        "#split the data into labeled and unlabeled sets (50/50 split as requested)\n",
        "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "#active learning parameters\n",
        "N_QUERIES = 20\n",
        "\n",
        "#base estimator & query strategy\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "query_strategy = uncertainty_sampling\n",
        "\n",
        "#active learner\n",
        "learner = ActiveLearner(\n",
        "    estimator=model,\n",
        "    X_training=X_labeled, y_training=y_labeled,\n",
        "    query_strategy=query_strategy\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(N_QUERIES):\n",
        "\n",
        "    learner.fit(X_labeled, y_labeled)\n",
        "    y_pred_unlabeled = learner.predict(X_unlabeled)\n",
        "\n",
        "    #calculate the uncertainty scores using standard deviation\n",
        "    uncertainty_scores = np.std(y_pred_unlabeled)\n",
        "\n",
        "    #query the most uncertain instances\n",
        "    query_idx = np.argmax(uncertainty_scores)\n",
        "\n",
        "    #add the selected data point to the labeled set and remove it from the unlabeled set\n",
        "    X_labeled = np.concatenate([X_labeled, X_unlabeled[query_idx].reshape(1, -1)])\n",
        "    y_labeled = np.concatenate([y_labeled, y_unlabeled[query_idx].reshape(1, )])\n",
        "    X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)\n",
        "    y_unlabeled = np.delete(y_unlabeled, query_idx)\n",
        "\n",
        "    #evaluation\n",
        "    y_pred_test = learner.predict(X_unlabeled)\n",
        "    mse = mean_squared_error(y_unlabeled, y_pred_test)\n",
        "    r2 = learner.score(X_unlabeled, y_unlabeled)\n",
        "    print(\"Query\", i + 1, \"- R2:\", r2)\n",
        "    print(\"Query\", i + 1, \"- Mean Squared Error on the test set:\", mse)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "print('Without Active Learning:')\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "X, y = diabetes.data, diabetes.target\n",
        "\n",
        "#split the data into training and test sets (50/50 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "#evaluation\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "r2 = learner.score(X_test, y_test)\n",
        "\n",
        "print(\"Mean Squared Error on the test set:\", mse)\n",
        "print(\"R2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uVNA3tX2swD",
        "outputId": "e2aef011-e27c-4209-9b2a-aa467592e1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1 - R2: 0.40951033496550693\n",
            "Query 1 - Mean Squared Error on the test set: 3364.265577727273\n",
            "\n",
            "\n",
            "Query 2 - R2: 0.41818404952514165\n",
            "Query 2 - Mean Squared Error on the test set: 3312.1580968036524\n",
            "\n",
            "\n",
            "Query 3 - R2: 0.4255138586445022\n",
            "Query 3 - Mean Squared Error on the test set: 3278.841186697248\n",
            "\n",
            "\n",
            "Query 4 - R2: 0.43061498176778756\n",
            "Query 4 - Mean Squared Error on the test set: 3248.612370506912\n",
            "\n",
            "\n",
            "Query 5 - R2: 0.42519752709728764\n",
            "Query 5 - Mean Squared Error on the test set: 3290.316887037037\n",
            "\n",
            "\n",
            "Query 6 - R2: 0.4220638083893722\n",
            "Query 6 - Mean Squared Error on the test set: 3311.265136744186\n",
            "\n",
            "\n",
            "Query 7 - R2: 0.4234099682493019\n",
            "Query 7 - Mean Squared Error on the test set: 3297.070135514018\n",
            "\n",
            "\n",
            "Query 8 - R2: 0.4200786795219793\n",
            "Query 8 - Mean Squared Error on the test set: 3292.0304596244127\n",
            "\n",
            "\n",
            "Query 9 - R2: 0.4156665193488416\n",
            "Query 9 - Mean Squared Error on the test set: 3323.7171679245284\n",
            "\n",
            "\n",
            "Query 10 - R2: 0.42579692344880593\n",
            "Query 10 - Mean Squared Error on the test set: 3273.2133682464455\n",
            "\n",
            "\n",
            "Query 11 - R2: 0.42871574578169636\n",
            "Query 11 - Mean Squared Error on the test set: 3263.0264914285713\n",
            "\n",
            "\n",
            "Query 12 - R2: 0.433397050773515\n",
            "Query 12 - Mean Squared Error on the test set: 3224.4419535885168\n",
            "\n",
            "\n",
            "Query 13 - R2: 0.43733831468352435\n",
            "Query 13 - Mean Squared Error on the test set: 3209.9569793269234\n",
            "\n",
            "\n",
            "Query 14 - R2: 0.42677816492758347\n",
            "Query 14 - Mean Squared Error on the test set: 3227.1781966183576\n",
            "\n",
            "\n",
            "Query 15 - R2: 0.4236126280170769\n",
            "Query 15 - Mean Squared Error on the test set: 3260.0411626213595\n",
            "\n",
            "\n",
            "Query 16 - R2: 0.42916197770392106\n",
            "Query 16 - Mean Squared Error on the test set: 3224.6689458536584\n",
            "\n",
            "\n",
            "Query 17 - R2: 0.4216887312847666\n",
            "Query 17 - Mean Squared Error on the test set: 3224.1474676470593\n",
            "\n",
            "\n",
            "Query 18 - R2: 0.404764097941097\n",
            "Query 18 - Mean Squared Error on the test set: 3297.016558128079\n",
            "\n",
            "\n",
            "Query 19 - R2: 0.41713614975798896\n",
            "Query 19 - Mean Squared Error on the test set: 3243.3251821782173\n",
            "\n",
            "\n",
            "Query 20 - R2: 0.4087682557836422\n",
            "Query 20 - Mean Squared Error on the test set: 3260.0887447761197\n",
            "\n",
            "\n",
            "Without Active Learning:\n",
            "Mean Squared Error on the test set: 3373.3676447963803\n",
            "R2: 0.4694732113546931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the application of active learning, it is observed that the R2 scores display gradual improvements with each additional query introduced. Simultaneously, we see a noticeable decline in mean square error as well, suggesting better predictive performance whilst decreasing prediction inaccuracies thanks to this particular approach employed. Further increasing the query steps does not considerably improve either of the result metrics.\n",
        "Experiments with other regressor models display a similar such improvement in both metrics."
      ],
      "metadata": {
        "id": "t2PWMDm_4ZR9"
      }
    }
  ]
}