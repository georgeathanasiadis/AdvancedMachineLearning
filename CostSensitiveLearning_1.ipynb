{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initialization"
      ],
      "metadata": {
        "id": "IJ7Az8xx4l_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#load the data\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "columns = [\"checking_account_status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
        "           \"savings_account_status\", \"employment_status\", \"installment_rate\", \"personal_status\",\n",
        "           \"other_debtors\", \"residence_history\", \"property\", \"age\", \"other_installment_plans\",\n",
        "           \"housing\", \"number_of_existing_credits\", \"job\", \"dependents\", \"telephone\", \"foreign_worker\", \"class\"]\n",
        "data = pd.read_csv(url, sep=\" \", header=None, names=columns)\n",
        "\n",
        "#define the feature columns and target column\n",
        "feature_cols = [\"checking_account_status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
        "                \"savings_account_status\", \"employment_status\", \"installment_rate\", \"personal_status\",\n",
        "                \"other_debtors\", \"residence_history\", \"property\", \"age\", \"other_installment_plans\",\n",
        "                \"housing\", \"number_of_existing_credits\", \"job\", \"dependents\", \"telephone\", \"foreign_worker\"]\n",
        "target_col = \"class\"\n",
        "\n",
        "#split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[feature_cols], data[target_col], test_size=0.2, random_state=42)\n",
        "\n",
        "#one-hot encode the categorical features\n",
        "cat_transformer = ColumnTransformer(transformers=[(\"onehot\", OneHotEncoder(), [0, 2, 3, 5, 6, 8, 9, 11, 14, 16, 18, 19])], sparse_threshold = 0)\n",
        "X_train = cat_transformer.fit_transform(X_train)\n",
        "X_test = cat_transformer.transform(X_test)\n",
        "\n",
        "#clculate the cost matrix\n",
        "cost_m = [[0, 5],\n",
        "          [1, 0]]\n",
        "#the \"problem\" is labeling a Bad client Good (FP = 5) and not so much the other way around (FN = 1)\n",
        "names = ['Random Forest', 'Linear SVM', 'Naive Bayes']\n",
        "classifiers = [RandomForestClassifier(n_estimators=100, random_state=0),\n",
        "               SVC(kernel='linear', probability=True), GaussianNB()]"
      ],
      "metadata": {
        "id": "EeMlZEgr4zl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pure approach - no weights taken into consideration:"
      ],
      "metadata": {
        "id": "XIv5OIo54-R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Pure approach - no weights taken into consideration\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(name)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=[\"Good\", \"Bad\"]))\n",
        "  conf_m = confusion_matrix(y_test, y_pred) # transpose to align with slides\n",
        "  print(conf_m)\n",
        "  print(np.sum(conf_m * cost_m))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrP6XpZi5D35",
        "outputId": "0845f042-dc66-4785-d872-59960ba7201c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.77      0.89      0.83       141\n",
            "         Bad       0.58      0.36      0.44        59\n",
            "\n",
            "    accuracy                           0.73       200\n",
            "   macro avg       0.68      0.62      0.63       200\n",
            "weighted avg       0.71      0.73      0.71       200\n",
            "\n",
            "[[126  15]\n",
            " [ 38  21]]\n",
            "113\n",
            "Linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.79      0.91      0.84       141\n",
            "         Bad       0.65      0.41      0.50        59\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.72      0.66      0.67       200\n",
            "weighted avg       0.74      0.76      0.74       200\n",
            "\n",
            "[[128  13]\n",
            " [ 35  24]]\n",
            "100\n",
            "Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.84      0.65      0.74       141\n",
            "         Bad       0.46      0.71      0.56        59\n",
            "\n",
            "    accuracy                           0.67       200\n",
            "   macro avg       0.65      0.68      0.65       200\n",
            "weighted avg       0.73      0.67      0.68       200\n",
            "\n",
            "[[92 49]\n",
            " [17 42]]\n",
            "262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear SVM model has the best accuracy (76%) and cost (100). It also has a pretty good accuracy and recall for the \"Good\" class, which is the one we're most concerned in properly predicting.\n",
        "\n",
        "When compared to the linear SVM model, the RandomForest model has greater recall for the \"Bad\" class but poorer precision and overall accuracy.\n",
        "\n",
        "The Naive Bayes model is the least accurate (67%) and the most expensive (262). This implies that it misclassifies many cases and has a high cost of misclassification."
      ],
      "metadata": {
        "id": "a12heU-N7jgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weighted apporach\n"
      ],
      "metadata": {
        "id": "Jpw_7-q45G_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weighted apporach:\")\n",
        "weights = np.zeros(y_train.shape[0])\n",
        "weights[np.where(y_train == 1)] = 1;\n",
        "weights[np.where(y_train == 2)] = 5;\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(name, \"(Weighted apporach)\")\n",
        "    clf.fit(X_train, y_train, weights)\n",
        "    pred_test = clf.predict(X_test)\n",
        "    print(classification_report(y_test, pred_test, target_names=[\"Good\", \"Bad\"]))\n",
        "    conf_m = confusion_matrix(y_test, pred_test) # transpose to align with slides\n",
        "    print(conf_m)\n",
        "    loss = np.sum(conf_m * cost_m)\n",
        "    print(\"%d\\n\" %loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y4LCwM95Kdw",
        "outputId": "96b1f493-6be4-405a-db5b-aee63894c864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted apporach:\n",
            "Random Forest (Weighted apporach)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.80      0.93      0.86       141\n",
            "         Bad       0.72      0.44      0.55        59\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.76      0.68      0.70       200\n",
            "weighted avg       0.78      0.79      0.77       200\n",
            "\n",
            "[[131  10]\n",
            " [ 33  26]]\n",
            "83\n",
            "\n",
            "Linear SVM (Weighted apporach)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.92      0.48      0.63       141\n",
            "         Bad       0.42      0.90      0.57        59\n",
            "\n",
            "    accuracy                           0.60       200\n",
            "   macro avg       0.67      0.69      0.60       200\n",
            "weighted avg       0.77      0.60      0.61       200\n",
            "\n",
            "[[67 74]\n",
            " [ 6 53]]\n",
            "376\n",
            "\n",
            "Naive Bayes (Weighted apporach)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.87      0.57      0.69       141\n",
            "         Bad       0.44      0.80      0.57        59\n",
            "\n",
            "    accuracy                           0.64       200\n",
            "   macro avg       0.66      0.69      0.63       200\n",
            "weighted avg       0.74      0.64      0.66       200\n",
            "\n",
            "[[81 60]\n",
            " [12 47]]\n",
            "312\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to the unweighted approach, the weighted approach showed some improvements in the performance metrics. For instance, the Random Forest classifier's accuracy and recall for identifying the \"Bad\" class improved, as well as the f1-score for predicting the \"Good\" class.\n",
        "\n",
        "However, the Linear SVM and Naive Bayes classifiers did not perform as well with the weighted strategy. The Linear SVM classifier's accuracy and recall for predicting the \"Good\" class decreased, while the Naive Bayes classifier's precision decreased for both classes. Additionally, except for the Random Forest classifier, all classifiers suffered greater losses with the weighted strategy.\n",
        "\n",
        "In conclusion, the weighted strategy produced mixed results and may not always lead to better performance. Therefore, it's essential to carefully consider the trade-offs between different performance measures and the costs associated with misclassification when selecting a classification strategy."
      ],
      "metadata": {
        "id": "UeABoDlI7pkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Over)sampling approach"
      ],
      "metadata": {
        "id": "KSCPnRzv5NDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"(Over)sampling approach:\")\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 559, 2: 559}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "#print(Counter(y_rs))\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(name, \"(Over)sampling approach\")\n",
        "    model = clf.fit(X_rs, y_rs)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"Good\", \"Bad\"]))\n",
        "    conf_m = confusion_matrix(y_test, y_pred) # transpose to align with slides\n",
        "    print(conf_m)\n",
        "    loss = np.sum(conf_m * cost_m)\n",
        "    print(\"%d\\n\" %loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlzV6CTh5PiA",
        "outputId": "e5f3860f-c21d-4d05-e87b-00a61cbfea5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Over)sampling approach:\n",
            "Random Forest (Over)sampling approach\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.81      0.82      0.81       141\n",
            "         Bad       0.55      0.53      0.54        59\n",
            "\n",
            "    accuracy                           0.73       200\n",
            "   macro avg       0.68      0.67      0.68       200\n",
            "weighted avg       0.73      0.73      0.73       200\n",
            "\n",
            "[[116  25]\n",
            " [ 28  31]]\n",
            "153\n",
            "\n",
            "Linear SVM (Over)sampling approach\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.91      0.62      0.73       141\n",
            "         Bad       0.48      0.85      0.61        59\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.69      0.73      0.67       200\n",
            "weighted avg       0.78      0.69      0.70       200\n",
            "\n",
            "[[87 54]\n",
            " [ 9 50]]\n",
            "279\n",
            "\n",
            "Naive Bayes (Over)sampling approach\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.89      0.54      0.67       141\n",
            "         Bad       0.43      0.85      0.57        59\n",
            "\n",
            "    accuracy                           0.63       200\n",
            "   macro avg       0.66      0.69      0.62       200\n",
            "weighted avg       0.76      0.63      0.64       200\n",
            "\n",
            "[[76 65]\n",
            " [ 9 50]]\n",
            "334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The findings of the (over)sampling strategy show that it outperforms the initial imbalanced dataset, although probably not as well as the weighted approach. The accuracy, recall, and f1-score for the minority class (Bad) for the Random Forest classifier increased marginally when compared to the initial imbalanced dataset.\n",
        "\n",
        "However, when compared to the weighted strategy, the performance of the Linear SVM and Naive Bayes classifiers declined. It's worth mentioning that the (over)sampling strategy has a smaller loss than the initial imbalanced dataset but a bigger loss than the weighted approach."
      ],
      "metadata": {
        "id": "nxJhBcnN8CfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost minimization without probability calibration"
      ],
      "metadata": {
        "id": "cUNpA3cE5SMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cost minimization without probability calibration\")\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(name, \"cost minimization without probability calibration\")\n",
        "    model = clf.fit(X_train, y_train)\n",
        "    y_pred_prob = model.predict_proba(X_test)\n",
        "    y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m)), axis=1) + 1\n",
        "    print(\"Class difference:\", set(y_test) - set(y_pred))\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"Good\", \"Bad\"]))\n",
        "    conf_m = confusion_matrix(y_test, y_pred) # transpose to align with slides\n",
        "    print(conf_m)\n",
        "    print(np.sum(conf_m * cost_m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u74mSUw5T9i",
        "outputId": "29587387-cf2c-4c32-9a0f-35e8514a62da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost minimization without probability calibration\n",
            "Random Forest cost minimization without probability calibration\n",
            "Class difference: {2}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.70      1.00      0.83       141\n",
            "         Bad       0.00      0.00      0.00        59\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.35      0.50      0.41       200\n",
            "weighted avg       0.50      0.70      0.58       200\n",
            "\n",
            "[[141   0]\n",
            " [ 59   0]]\n",
            "59\n",
            "Linear SVM cost minimization without probability calibration\n",
            "Class difference: {2}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.70      1.00      0.83       141\n",
            "         Bad       0.00      0.00      0.00        59\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.35      0.50      0.41       200\n",
            "weighted avg       0.50      0.70      0.58       200\n",
            "\n",
            "[[141   0]\n",
            " [ 59   0]]\n",
            "59\n",
            "Naive Bayes cost minimization without probability calibration\n",
            "Class difference: set()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.80      0.76      0.78       141\n",
            "         Bad       0.49      0.56      0.52        59\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.65      0.66      0.65       200\n",
            "weighted avg       0.71      0.70      0.71       200\n",
            "\n",
            "[[107  34]\n",
            " [ 26  33]]\n",
            "196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cost minimization strategy without probability calibration appears to simply forecast all samples to belong to the majority class for the Random Forest and Linear SVM classifiers, resulting in very poor recall and F1-score for the minority class (Bad). The confusion matrix for both classifiers shows that all predicted samples are in the Good class, and the cost associated with this approach is simply the cost of misclassifying the minority class for all samples, which is equal to the number of minority class samples in the test set.\n",
        "\n",
        "The cost minimization strategy without probability calibration, on the other hand, outperforms the Naive Bayes classifier and accurately predicts certain minority class samples. The confusion matrix reveals that the minority class has some genuine positive and false positive predictions, resulting in a non-zero cost. The classification report demonstrates that the minority class has superior accuracy, recall, and F1-score than the Random Forest and Linear SVM classifiers.\n",
        "\n",
        "The warning \"Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples\" indicates that there are only samples of one class in the predicted values - this seems like a technical issue that I could not overcome."
      ],
      "metadata": {
        "id": "wNgxknag870h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost minimization with isotonic/sigmoid calibration"
      ],
      "metadata": {
        "id": "xbjqgL2a5a4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cost minimization with isotonic/sigmoid calibration\")\n",
        "for name, clf in zip(names, classifiers):\n",
        "    cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3) #switch the \"method\" field to isotonic/sigmoid to try both\n",
        "    print(\"Cost minimization (with sigmoid calibration):\", name)\n",
        "    model = cc.fit(X_train, y_train)\n",
        "    y_pred_prob = model.predict_proba(X_test)\n",
        "    y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m)), axis=1) + 1\n",
        "    print(\"Class difference:\", set(y_test) - set(y_pred))\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"Good\", \"Bad\"]))\n",
        "    conf_m = confusion_matrix(y_test, y_pred) # transpose to align with slides\n",
        "    print(conf_m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW4SBX_y5VxK",
        "outputId": "6fc8963a-4520-4d24-ea1a-a6cda891588a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost minimization with isotonic/sigmoid calibration\n",
            "Cost minimization (with sigmoid calibration): Random Forest\n",
            "Class difference: {2}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.70      1.00      0.83       141\n",
            "         Bad       0.00      0.00      0.00        59\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.35      0.50      0.41       200\n",
            "weighted avg       0.50      0.70      0.58       200\n",
            "\n",
            "[[141   0]\n",
            " [ 59   0]]\n",
            "Cost minimization (with sigmoid calibration): Linear SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class difference: {2}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.70      1.00      0.83       141\n",
            "         Bad       0.00      0.00      0.00        59\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.35      0.50      0.41       200\n",
            "weighted avg       0.50      0.70      0.58       200\n",
            "\n",
            "[[141   0]\n",
            " [ 59   0]]\n",
            "Cost minimization (with sigmoid calibration): Naive Bayes\n",
            "Class difference: {2}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.70      1.00      0.83       141\n",
            "         Bad       0.00      0.00      0.00        59\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.35      0.50      0.41       200\n",
            "weighted avg       0.50      0.70      0.58       200\n",
            "\n",
            "[[141   0]\n",
            " [ 59   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that the classifiers are underperforming because they all have a precision of 0.0 for the \"Bad\" class and an F1-score of 0.0. This suggests that the classifiers are completely incapable of identifying the \"Bad\" class. Furthermore, several \"UndefinedMetricWarning\" messages again indicate that there are no expected samples for the \"Bad\" class, leaving the accuracy and F1-score undefined."
      ],
      "metadata": {
        "id": "BNFw4G819oOj"
      }
    }
  ]
}