{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initialization"
      ],
      "metadata": {
        "id": "BU32TFDTJBgd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_oJV1R5a3BQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.model_selection import cross_validate\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "from collections import Counter\n",
        "\n",
        "#load dataset\n",
        "#data = pd.read_csv('carclaims.csv')\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['carclaims.csv']))# Dataset is now stored in a Pandas Dataframe\n",
        "#separate the target variable (FraudFound) from the features\n",
        "data['FraudFound'] = data['FraudFound'].replace({'Yes': 1, 'No': 0})\n",
        "y = data['FraudFound']\n",
        "data = data.drop(['FraudFound'], axis=1)\n",
        "\n",
        "X = pd.get_dummies(data, columns = ['Month', 'DayOfWeek','Make', 'AccidentArea','DayOfWeekClaimed', 'MonthClaimed',\n",
        "                                                       'Sex','MaritalStatus', 'Fault','PolicyType','VehicleCategory','VehiclePrice',\n",
        "                                                       'Days:Policy-Accident','Days:Policy-Claim','PastNumberOfClaims','AgeOfVehicle','AgeOfPolicyHolder',\n",
        "                                                       'PoliceReportFiled','WitnessPresent','AgentType',\n",
        "                                                       'NumberOfSuppliments','AddressChange-Claim','NumberOfCars','BasePolicy'])\n",
        "\n",
        "#split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "QHi2d2ZJJBz8",
        "outputId": "b666f02b-0766-4dbe-b4ba-b110b3cc44bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a0f7e272-8fbe-427c-8a34-9b6db901bf07\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a0f7e272-8fbe-427c-8a34-9b6db901bf07\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving carclaims.csv to carclaims.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pure approach, no class imbalance taken into consideration"
      ],
      "metadata": {
        "id": "MNFk2mjrJExL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "names = ['Random Forest', 'Naive Bayes', 'Linear SVM']\n",
        "classifiers = [RandomForestClassifier(n_estimators=100, random_state=0),\n",
        "               GaussianNB() , SVC(kernel='linear')]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(name)\n",
        "    model = clf\n",
        "    model.fit(X_train, y_train)\n",
        "    #predict on the test set and evaluate the model performance\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "4Qu3GtPwKD3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a7a5c6-1a41-4463-d036-5f5ae3c56181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      2899\n",
            "           1       1.00      0.02      0.03       185\n",
            "\n",
            "    accuracy                           0.94      3084\n",
            "   macro avg       0.97      0.51      0.50      3084\n",
            "weighted avg       0.94      0.94      0.91      3084\n",
            "\n",
            "Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.75      0.85      2899\n",
            "           1       0.15      0.66      0.24       185\n",
            "\n",
            "    accuracy                           0.75      3084\n",
            "   macro avg       0.56      0.71      0.54      3084\n",
            "weighted avg       0.92      0.75      0.81      3084\n",
            "\n",
            "Linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97      2899\n",
            "           1       0.08      0.01      0.02       185\n",
            "\n",
            "    accuracy                           0.93      3084\n",
            "   macro avg       0.51      0.50      0.49      3084\n",
            "weighted avg       0.89      0.93      0.91      3084\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The recall (sensitivity) for all classifiers is quite poor for the minority\n",
        "class (FraudFound = 1). This suggests that the models are unable to accurately detect the majority of false claims.\n",
        "\n",
        "The accuracy for the minority class is likewise poor for Random Forest and Linear SVM, indicating that the majority of projected fraudulent claims are not fraudulent.\n",
        "\n",
        "Because of the low recall and accuracy, the F1-score for the minority class is low for all classifiers.\n",
        "\n",
        "The accuracy of all classifiers is relatively high, which is misleading in this situation due to the unbalanced dataset.\n",
        "\n",
        "All classifiers had low macro-averaged accuracy, recall, and F1-score, indicating poor performance on the minority class, again due to data imbalance.\n"
      ],
      "metadata": {
        "id": "7k0m2Mj4qyxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Synthetic Oversampling"
      ],
      "metadata": {
        "id": "H7vj5jKAN3XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Synthetic Oversampling\n",
        "for name, clf in zip(names, classifiers):\n",
        "    #create a pipeline\n",
        "    pipeline = make_pipeline(clf)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    #classify and report the results\n",
        "    print(name)\n",
        "    print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "    pipeline = make_pipeline(clf)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(name, \"with balanced weights\")\n",
        "    print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "    pipeline = make_pipeline(SMOTE(random_state=3, k_neighbors=5),\n",
        "                             clf)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(name, \" with SMOTE\")\n",
        "    print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "btSgKA2mQdl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e8ade2-44b1-4b9e-d6a0-b218692c54ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      1.00      0.02      0.97      0.13      0.02      2899\n",
            "          1       1.00      0.02      1.00      0.03      0.13      0.01       185\n",
            "\n",
            "avg / total       0.94      0.94      0.08      0.91      0.13      0.02      3084\n",
            "\n",
            "Random Forest with balanced weights\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      1.00      0.02      0.97      0.13      0.02      2899\n",
            "          1       1.00      0.02      1.00      0.03      0.13      0.01       185\n",
            "\n",
            "avg / total       0.94      0.94      0.08      0.91      0.13      0.02      3084\n",
            "\n",
            "Random Forest  with SMOTE\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      1.00      0.01      0.97      0.10      0.01      2899\n",
            "          1       1.00      0.01      1.00      0.02      0.10      0.01       185\n",
            "\n",
            "avg / total       0.94      0.94      0.07      0.91      0.10      0.01      3084\n",
            "\n",
            "Naive Bayes\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.75      0.66      0.85      0.71      0.50      2899\n",
            "          1       0.15      0.66      0.75      0.24      0.71      0.49       185\n",
            "\n",
            "avg / total       0.92      0.75      0.67      0.81      0.71      0.50      3084\n",
            "\n",
            "Naive Bayes with balanced weights\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.75      0.66      0.85      0.71      0.50      2899\n",
            "          1       0.15      0.66      0.75      0.24      0.71      0.49       185\n",
            "\n",
            "avg / total       0.92      0.75      0.67      0.81      0.71      0.50      3084\n",
            "\n",
            "Naive Bayes  with SMOTE\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.95      0.89      0.27      0.92      0.49      0.26      2899\n",
            "          1       0.14      0.27      0.89      0.18      0.49      0.23       185\n",
            "\n",
            "avg / total       0.90      0.85      0.31      0.88      0.49      0.25      3084\n",
            "\n",
            "Linear SVM\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      0.99      0.01      0.97      0.10      0.01      2899\n",
            "          1       0.08      0.01      0.99      0.02      0.10      0.01       185\n",
            "\n",
            "avg / total       0.89      0.93      0.07      0.91      0.10      0.01      3084\n",
            "\n",
            "Linear SVM with balanced weights\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      0.99      0.01      0.97      0.10      0.01      2899\n",
            "          1       0.08      0.01      0.99      0.02      0.10      0.01       185\n",
            "\n",
            "avg / total       0.89      0.93      0.07      0.91      0.10      0.01      3084\n",
            "\n",
            "Linear SVM  with SMOTE\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      0.99      0.04      0.97      0.21      0.05      2899\n",
            "          1       0.27      0.04      0.99      0.07      0.21      0.04       185\n",
            "\n",
            "avg / total       0.90      0.94      0.10      0.91      0.21      0.05      3084\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metrics here suggest that the Random Forest model with no resampling approaches performs the best. It has the highest F1-score of all models, which is 0.91. Although the Naive Bayes model with SMOTE has the greatest recall score for the minority class, it has a lower overall F1-score than the Random Forest model without any resampling strategies. The Linear SVM models outperform the others, with poor recall scores for the minority class.\n",
        "\n",
        "However if each model is individually assessed, SMOTE & weight balancing seem to slightly improve several metrics, for instance the avg F1 score."
      ],
      "metadata": {
        "id": "F_enJ7QsSwtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NearMiss\n"
      ],
      "metadata": {
        "id": "xNDACqFQ2kR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NearMiss\n",
        "for name, clf in zip(names, classifiers):\n",
        "    pipeline = make_pipeline(NearMiss(version=1),\n",
        "                             clf)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    #classify and report the results\n",
        "    print(name, \"with near miss 1\")\n",
        "    print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "    #create a pipeline\n",
        "    pipeline = make_pipeline(NearMiss(version=2),\n",
        "                             clf)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(name, \"with near miss 2\")\n",
        "    print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "    print(name, \"with near miss 3\") # See issue in GitHub\n",
        "    pipeline = make_pipeline(NearMiss(version=3, n_neighbors_ver3=3),\n",
        "                             clf)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWbm9i792oUD",
        "outputId": "f3081ee0-89b9-4afc-d25d-c57bbb6a1c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest with near miss 1\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.62      0.88      0.76      0.74      0.53      2899\n",
            "          1       0.13      0.88      0.62      0.22      0.74      0.56       185\n",
            "\n",
            "avg / total       0.94      0.64      0.86      0.73      0.74      0.53      3084\n",
            "\n",
            "Random Forest with near miss 2\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.29      0.95      0.45      0.52      0.26      2899\n",
            "          1       0.08      0.95      0.29      0.15      0.52      0.29       185\n",
            "\n",
            "avg / total       0.93      0.33      0.91      0.43      0.52      0.26      3084\n",
            "\n",
            "Random Forest with near miss 3\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.62      0.88      0.76      0.74      0.54      2899\n",
            "          1       0.13      0.88      0.62      0.23      0.74      0.56       185\n",
            "\n",
            "avg / total       0.94      0.64      0.87      0.73      0.74      0.54      3084\n",
            "\n",
            "Naive Bayes with near miss 1\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.95      0.81      0.37      0.87      0.54      0.31      2899\n",
            "          1       0.11      0.37      0.81      0.17      0.54      0.28       185\n",
            "\n",
            "avg / total       0.90      0.78      0.39      0.83      0.54      0.31      3084\n",
            "\n",
            "Naive Bayes with near miss 2\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.98      0.17      0.94      0.29      0.40      0.15      2899\n",
            "          1       0.07      0.94      0.17      0.12      0.40      0.17       185\n",
            "\n",
            "avg / total       0.92      0.21      0.89      0.28      0.40      0.15      3084\n",
            "\n",
            "Naive Bayes with near miss 3\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.62      0.86      0.76      0.73      0.52      2899\n",
            "          1       0.13      0.86      0.62      0.22      0.73      0.55       185\n",
            "\n",
            "avg / total       0.93      0.64      0.85      0.73      0.73      0.52      3084\n",
            "\n",
            "Linear SVM with near miss 1\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.98      0.61      0.84      0.75      0.72      0.50      2899\n",
            "          1       0.12      0.84      0.61      0.21      0.72      0.52       185\n",
            "\n",
            "avg / total       0.93      0.63      0.82      0.72      0.72      0.50      3084\n",
            "\n",
            "Linear SVM with near miss 2\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.58      0.90      0.73      0.72      0.51      2899\n",
            "          1       0.12      0.90      0.58      0.21      0.72      0.54       185\n",
            "\n",
            "avg / total       0.94      0.60      0.88      0.70      0.72      0.51      3084\n",
            "\n",
            "Linear SVM with near miss 3\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.60      0.93      0.75      0.75      0.54      2899\n",
            "          1       0.13      0.93      0.60      0.23      0.75      0.58       185\n",
            "\n",
            "avg / total       0.94      0.62      0.91      0.72      0.75      0.55      3084\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the results, the Random Forest model with NearMiss 1 seems to be the best performing model. It has the greatest accuracy (0.99) and f1 score (0.73) of any model, indicating that it can properly identify the positive class (frauds) while reducing false positives.\n",
        "\n",
        "With a precision of 0.95 and a f1 score of 0.83, the Naive Bayes model employing NearMiss 1 fared rather well as well. However, its recall score (0.78) is lower than the Random Forest model with NearMiss 1 (0.64), suggesting that it may be missing some genuine positives.\n",
        "\n",
        "NearMiss1 & 3 seem to generally outperform NearMiss2 in several metrics, for instance, the F1 avg score.\n",
        "\n"
      ],
      "metadata": {
        "id": "wJnhAJICp-LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EasyEnsemble"
      ],
      "metadata": {
        "id": "o_l_CDVK24R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    scoring = ['accuracy', 'balanced_accuracy']\n",
        "\n",
        "    algs = []\n",
        "    rf = RandomForestClassifier()\n",
        "    algs.append([rf, \"Random Forrest\"])\n",
        "    nb = GaussianNB()\n",
        "    algs.append([nb, \"Naive Bayes\"])\n",
        "    nb = SVC(kernel='linear', probability=True)\n",
        "    algs.append([nb, \"Linear SVM\"])\n",
        "    ee = EasyEnsembleClassifier(random_state=42)\n",
        "    algs.append([ee, \"Easy Ensemble\"])\n",
        "\n",
        "    for c, d in algs:\n",
        "        print(\"\\n\" + d)\n",
        "        scores = cross_validate(c, X, y, scoring=scoring, cv=10, return_train_score=False)\n",
        "        for s in scoring:\n",
        "            print(\"%s: %0.2f (+/- %0.2f)\" % (s, scores[\"test_\" + s].mean(), scores[\"test_\" + s].std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL8D7fJw26As",
        "outputId": "f0aae6dd-886e-4f78-aea8-86c0ce1eca97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forrest\n",
            "accuracy: 0.93 (+/- 0.02)\n",
            "balanced_accuracy: 0.51 (+/- 0.02)\n",
            "\n",
            "Naive Bayes\n",
            "accuracy: 0.73 (+/- 0.02)\n",
            "balanced_accuracy: 0.53 (+/- 0.05)\n",
            "\n",
            "Linear SVM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest algorithm achieved a high accuracy of 0.93 with a low standard deviation of 0.02. However, the balanced accuracy is only 0.51 with a low standard deviation of 0.02.\n",
        "\n",
        "The Naive Bayes algorithm achieved a lower accuracy of 0.73 with a similar standard deviation of 0.02. However, the balanced accuracy is slightly higher at 0.53 with a higher standard deviation of 0.05.\n",
        "\n",
        "Unfortunately I never produced results for Linear SVM as my longest running session before I got disconnected was 6h 22m (hosted environment), still not sufficient for the results to be produced. A more optimal conversion from categorical to numeric than the one I used would most likely speed up the execution."
      ],
      "metadata": {
        "id": "3jn01SfnybqS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1fs1d1wzQFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}